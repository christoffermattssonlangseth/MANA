{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183bd911",
   "metadata": {},
   "source": [
    "# Use MANA for the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vnxqckvtglg",
   "metadata": {},
   "source": [
    "## MANA-7: Full Dataset Implementation\n",
    "\n",
    "**Objective:** Apply MANA to the complete dataset with all samples.\n",
    "\n",
    "**Workflow:**\n",
    "1. ‚úÖ Load full dataset (with fix for h5ad reading issues)\n",
    "2. ‚úÖ Run scVI on all samples for unified latent representation\n",
    "3. ‚úÖ Build spatial neighborhood graphs\n",
    "4. ‚úÖ Apply MANA with optimal parameters (gaussian kernel, hop_decay=0.2, n_layers=3)\n",
    "5. ‚úÖ Cluster cells in MANA feature space\n",
    "6. ‚úÖ Visualize results across all samples\n",
    "7. ‚úÖ Evaluate clustering quality (spatial & expression coherence)\n",
    "8. ‚úÖ Optional: Compare with CellCharter on full dataset\n",
    "\n",
    "**Key Parameters (from MANA-6 benchmark):**\n",
    "- `distance_kernel='gaussian'` (winner with 0.693 composite score)\n",
    "- `hop_decay=0.2` (optimal from MANA-4)\n",
    "- `n_layers=3` (optimal balance from MANA-5)\n",
    "- `aggregations='mean'` (standard approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7056d54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee57fabd",
   "metadata": {},
   "source": [
    "## read entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74813816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for anndata reading issues with problematic .uns entries\n",
    "# The error occurs when some .uns entries can't be deserialized\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ff343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded: 877141 cells √ó 5101 genes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    adata = sc.read_h5ad('/Volumes/processing2/RRmap/data/EAE_proseg_clustered_louvain_leiden_all_sections_annotated_rotated_cellcharter_neigh2_251219.h5ad')\n",
    "    print(f\"Successfully loaded: {adata.shape[0]} cells √ó {adata.shape[1]} genes\")\n",
    "except Exception as e:\n",
    "    print(f\"Initial read failed: {e}\")\n",
    "    print(\"Attempting to read with backed mode and then copy...\")\n",
    "    \n",
    "    # Read in backed mode (doesn't load everything into memory)\n",
    "    adata_backed = sc.read_h5ad(\n",
    "        '/Volumes/processing2/RRmap/data/EAE_proseg_clustered_louvain_leiden_all_sections_annotated_rotated_cellcharter_neigh2_251219.h5ad',\n",
    "        backed='r'\n",
    "    )\n",
    "    \n",
    "    # Copy to memory, which skips problematic .uns entries\n",
    "    adata = adata_backed.to_memory()\n",
    "    \n",
    "    print(f\"Successfully loaded: {adata.shape[0]} cells √ó {adata.shape[1]} genes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9s35b0xoslj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cells: 877,141\n",
      "Total genes: 5,101\n",
      "\n",
      "Samples: 107\n",
      "\n",
      "Available .obs columns:\n",
      "['cell', 'centroid_x', 'centroid_y', 'centroid_z', 'component', 'volume', 'surface_area', 'scale', 'region', 'sample_id', 'proseg_cluster', 'output_folder', 'Num', 'n_genes', 'n_counts', 'louvain_0.5', 'louvain_1', 'louvain_1.5', 'louvain_2', 'louvain_2.5', 'louvain_3', 'louvain_3.5', 'Cluster', 'Level1', 'Level2', 'Level3', 'Level3.1', 'grid_label', 'rbd_domain', 'rbd_domain_0.1', 'rbd_domain_0.2', 'rbd_domain_0.3', 'rbd_domain_0.5', 'rbd_domain_0.6', 'rbd_domain_0.7', 'rbd_domain_0.8', 'rbd_domain_0.9', 'rbd_domain_1.1', 'rbd_domain_1', 'rbd_domain_1.25', 'rbd_domain_1.4', 'rbd_domain_1.5', 'leiden_0.5', 'leiden_1', 'leiden_1.5', 'leiden_2', 'leiden_2.5', 'leiden_3', 'leiden_3.5', 'sample_name', 'course', 'condition', 'model', 'cytetype_annotation_louvain_3.5', 'cytetype_cellOntologyTerm_louvain_3.5', 'cluster_id', 'author_label', 'annotation', 'Class', 'state', 'CL_term', 'CL_term_id', 'confidence', 'author_label_similarity_score', 'cluster_cellcharter_auto', 'cluster_cellcharter_13', 'cluster_cellcharter_15', 'cluster_cellcharter_9', 'cluster_cellcharter_30', 'cluster_cellcharter_50', 'cluster_cellcharter_25', 'cluster_cellcharter_2', 'cluster_cellcharter_5', 'cluster_cellcharter_10', 'cluster_cellcharter_20', 'cluster_cellcharter_40', 'anno_L3', 'anno_L2', 'anno_L1', 'course_ordered', 'compartment_anno']\n",
      "\n",
      "Available .obsm keys:\n",
      "['X_pca', 'X_umap', 'spatial']\n",
      "\n",
      "Available .uns keys:\n",
      "['Class_colors', 'Cluster_colors', 'Level1_colors', 'Level2_colors', 'Level3.1_colors', 'Level3_colors', 'anno_L1_colors', 'cluster_cellcharter_10_colors', 'cluster_cellcharter_10_nhood_enrichment', 'compartment_anno_colors', 'condition_colors', 'confidence_colors', 'course_colors', 'cytetype_annotation_louvain_3.5_colors', 'cytetype_jobDetails', 'cytetype_results', 'leiden_0.5', 'leiden_0.5_colors', 'leiden_1', 'leiden_1.5', 'leiden_1.5_colors', 'leiden_1_colors', 'leiden_2', 'leiden_2.5', 'leiden_2.5_colors', 'leiden_2_colors', 'leiden_3', 'leiden_3.5', 'leiden_3.5_colors', 'leiden_3_colors', 'log1p', 'louvain_0.5', 'louvain_0.5_colors', 'louvain_1', 'louvain_1.5', 'louvain_1.5_colors', 'louvain_1_colors', 'louvain_2', 'louvain_2.5', 'louvain_2.5_colors', 'louvain_2_colors', 'louvain_3', 'louvain_3.5', 'louvain_3.5_colors', 'louvain_3_colors', 'model_colors', 'neighbors', 'pca', 'rank_genes_groups', 'rbd_domain_0.1_colors', 'rbd_domain_0.2_colors', 'rbd_domain_0.3_colors', 'rbd_domain_0.5_colors', 'rbd_domain_0.6_colors', 'rbd_domain_0.7_colors', 'rbd_domain_0.8_colors', 'rbd_domain_0.9_colors', 'rbd_domain_1.1_colors', 'rbd_domain_1.25_colors', 'rbd_domain_1.4_colors', 'rbd_domain_1.5_colors', 'rbd_domain_1_colors', 'rbd_domain_colors', 'region_colors', 'sample_id_order_by_course_region', 'sample_name_colors', 'state_colors', 'umap']\n"
     ]
    }
   ],
   "source": [
    "# Check data structure\n",
    "print(f\"Total cells: {adata.n_obs:,}\")\n",
    "print(f\"Total genes: {adata.n_vars:,}\")\n",
    "print(f\"\\nSamples: {adata.obs['sample_id'].nunique() if 'sample_id' in adata.obs else 'sample_id not found'}\")\n",
    "print(f\"\\nAvailable .obs columns:\\n{list(adata.obs.columns)}\")\n",
    "print(f\"\\nAvailable .obsm keys:\\n{list(adata.obsm.keys())}\")\n",
    "print(f\"\\nAvailable .uns keys:\\n{list(adata.uns.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wj5yi7bboh",
   "metadata": {},
   "source": [
    "## Part 1: Run scVI on All Samples\n",
    "\n",
    "We need to train scVI on the full dataset to get a unified latent representation across all samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ypoj80148dm",
   "metadata": {},
   "source": [
    "### Should we subset to highly variable genes (HVGs)?\n",
    "\n",
    "**Answer: NO** - scVI is designed to use all genes.\n",
    "\n",
    "**Why use all 5,101 genes?**\n",
    "- ‚úÖ scVI's neural network learns which genes are informative during training\n",
    "- ‚úÖ \"Non-variable\" genes can still contain cell type-specific information\n",
    "- ‚úÖ Gene selection was designed for PCA (linear methods), not deep learning\n",
    "- ‚úÖ scVI authors explicitly recommend using all genes\n",
    "- ‚úÖ With only 5,101 genes, computational cost is minimal\n",
    "\n",
    "**When to consider HVGs:**\n",
    "- ‚ö†Ô∏è Only if you have >20,000 genes AND severe memory constraints\n",
    "- Even then, scVI performance often degrades with gene subsetting\n",
    "\n",
    "**Our case:** 5,101 genes is already a reasonable number. Using all genes will give the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ma9siu0kjla",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all 5,101 genes for scVI training\n",
      "Number of cells: 877,141\n",
      "\n",
      "Total parameters to model: 4,474,296,241\n",
      "\n",
      "--- For comparison only (NOT recommended) ---\n",
      "If we selected top 2,000 HVGs: 1,754,282,000 parameters\n",
      "Information loss: 60.8% of genes discarded\n",
      "\n",
      "Conclusion: Using all 5,101 genes ‚úì\n"
     ]
    }
   ],
   "source": [
    "# Verify we're using all genes\n",
    "print(f\"Using all {adata.n_vars:,} genes for scVI training\")\n",
    "print(f\"Number of cells: {adata.n_obs:,}\")\n",
    "print(f\"\\nTotal parameters to model: {adata.n_obs * adata.n_vars:,}\")\n",
    "\n",
    "# For reference: if we had used HVG selection\n",
    "# (we're NOT doing this, just showing for comparison)\n",
    "print(f\"\\n--- For comparison only (NOT recommended) ---\")\n",
    "print(f\"If we selected top 2,000 HVGs: {adata.n_obs * 2000:,} parameters\")\n",
    "print(f\"Information loss: {(1 - 2000/adata.n_vars)*100:.1f}% of genes discarded\")\n",
    "print(f\"\\nConclusion: Using all {adata.n_vars:,} genes ‚úì\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hotio4vu9it",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christoffer/miniconda3/envs/cellcharter-env-new/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scVI setup complete. Batch key: sample_id\n",
      "Number of batches: 107\n"
     ]
    }
   ],
   "source": [
    "import scvi\n",
    "\n",
    "# Set up scVI\n",
    "# Assumes you have a 'sample_id' or similar batch key\n",
    "batch_key = 'sample_id'  # Adjust this to your actual batch column name\n",
    "\n",
    "# Setup anndata for scVI\n",
    "scvi.model.SCVI.setup_anndata(\n",
    "    adata,\n",
    "    layer=None,  # Use .X (raw counts)\n",
    "    batch_key=batch_key,  # Important: correct for batch effects between samples\n",
    ")\n",
    "\n",
    "print(f\"scVI setup complete. Batch key: {batch_key}\")\n",
    "print(f\"Number of batches: {adata.obs[batch_key].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reb7h73r1fn",
   "metadata": {},
   "source": [
    "### Performance Optimization for Large Dataset\n",
    "\n",
    "For 877K cells on MPS, we need to optimize training speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pcz95nlrccq",
   "metadata": {},
   "source": [
    "**Why is training slow at 100s/epoch?**\n",
    "\n",
    "For 877K cells on MPS with batch_size=512:\n",
    "- ‚ùå **Too many batches**: 877,141 / 512 = ~1,710 batches per epoch\n",
    "- ‚ùå **Frequent CPU‚ÜíGPU transfers**: Each batch requires data transfer\n",
    "- ‚ùå **MPS sparse‚Üídense overhead**: Converting sparse matrices on MPS is slow\n",
    "\n",
    "**Solutions:**\n",
    "1. ‚úÖ **Increase batch_size to 2048-4096**: Reduces batches to ~400-200 per epoch\n",
    "2. ‚úÖ **Keep dl_num_workers=0**: MPS doesn't benefit from multiprocessing\n",
    "3. ‚ö†Ô∏è **Consider CPU fallback**: For very sparse data, CPU can actually be faster than MPS\n",
    "4. ‚úÖ **Reduce max_epochs with early stopping**: Less total training time\n",
    "\n",
    "**Expected improvement:** \n",
    "- With batch_size=2048: ~25-40s/epoch (2.5-4√ó faster)\n",
    "- With batch_size=4096: ~15-25s/epoch (4-6√ó faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1435r0l57wv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data backed: False\n",
      "Data shape: (877141, 5101)\n",
      "Data type (.X): <class 'scipy.sparse._csr.csr_matrix'>\n",
      "\n",
      "PyTorch MPS available: True\n",
      "PyTorch MPS built: True\n",
      "\n",
      "Matrix sparsity: 84.35%\n",
      "Non-zero elements: 700,034,494\n"
     ]
    }
   ],
   "source": [
    "# Optimization 1: Increase batch size significantly\n",
    "# For 877K cells, batch_size=512 is too small (causes frequent CPU‚ÜíGPU transfers)\n",
    "# MPS can handle much larger batches\n",
    "scvi.settings.batch_size = 2048  # or even 4096 if memory allows\n",
    "\n",
    "# Optimization 2: Set num_workers to 0 for MPS (you already have this)\n",
    "scvi.settings.dl_num_workers = 0  # MPS doesn't benefit from multiprocessing\n",
    "\n",
    "# Optimization 3: Check if data is in memory (not backed mode)\n",
    "print(f\"Data backed: {adata.isbacked}\")\n",
    "print(f\"Data shape: {adata.shape}\")\n",
    "print(f\"Data type (.X): {type(adata.X)}\")\n",
    "\n",
    "# Optimization 4: Verify PyTorch is using MPS\n",
    "import torch\n",
    "print(f\"\\nPyTorch MPS available: {torch.backends.mps.is_available()}\")\n",
    "print(f\"PyTorch MPS built: {torch.backends.mps.is_built()}\")\n",
    "\n",
    "# Check memory usage\n",
    "if hasattr(adata.X, 'data'):\n",
    "    sparsity = 1 - (adata.X.nnz / (adata.n_obs * adata.n_vars))\n",
    "    print(f\"\\nMatrix sparsity: {sparsity:.2%}\")\n",
    "    print(f\"Non-zero elements: {adata.X.nnz:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ju2gjlh6ra",
   "metadata": {},
   "source": [
    "### Debugging: Still Slow After Batch Size Increase?\n",
    "\n",
    "If you're still seeing ~100s/epoch with larger batch_size, let's diagnose the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knjlwg9z51l",
   "metadata": {},
   "source": [
    "## üö® Diagnosis: Why MPS is Slow\n",
    "\n",
    "Based on your diagnostics:\n",
    "\n",
    "### Your Data:\n",
    "- **877,141 cells √ó 5,101 genes**\n",
    "- **84.35% sparsity** (700M non-zero elements)\n",
    "- **Sparse: 8GB, Dense: 17GB** (2.1√ó expansion)\n",
    "- **int64 dtype** (unnecessarily large)\n",
    "\n",
    "### The Problem:\n",
    "Every batch, MPS must:\n",
    "1. ‚úÖ Sample 2,048 cells from sparse CSR (fast)\n",
    "2. ‚ùå **Convert sparse ‚Üí dense** (8GB ‚Üí 17GB, CPU-bound)\n",
    "3. ‚ùå **Copy to MPS device** (memory transfer bottleneck)\n",
    "4. ‚úÖ Process on MPS (okay)\n",
    "5. ‚ùå **Repeat 429 times per epoch**\n",
    "\n",
    "**Result:** 100 seconds per epoch because of sparse‚Üídense conversion overhead!\n",
    "\n",
    "### The Solution: **Use CPU**\n",
    "- CPU can work directly with dense data in main memory\n",
    "- No device transfer overhead\n",
    "- Better optimized for sparse operations\n",
    "- Parallel data loading with multiple workers\n",
    "\n",
    "**Expected speedup: 2-3√ó** (100s ‚Üí 30-50s per epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fenam0mg8ka",
   "metadata": {},
   "source": [
    "**Important:** The batch_size must be set **BEFORE** calling `model.train()`. If you already created a model, the batch_size might not have updated. You need to:\n",
    "\n",
    "1. Set `scvi.settings.batch_size = 2048` (or desired size)\n",
    "2. Then create model: `model = scvi.model.SCVI(...)`\n",
    "3. Then train: `model.train(...)`\n",
    "\n",
    "If you set batch_size AFTER creating the model, it won't take effect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "gpgymqnlktw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Diagnostic Information ===\n",
      "\n",
      "scvi.settings.batch_size: 2048\n",
      "scvi.settings.dl_num_workers: 0\n",
      "\n",
      "PyTorch device available:\n",
      "  MPS available: True\n",
      "  MPS built: True\n",
      "  CUDA available: False\n",
      "\n",
      "Data information:\n",
      "  Shape: (877141, 5101)\n",
      "  Backed: False\n",
      "  .X type: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "  .X dtype: int64\n",
      "\n",
      "Expected batches per epoch: 429\n",
      "  (877,141 cells / 2048 batch_size)\n",
      "\n",
      "Matrix sparsity: 84.35%\n",
      "Non-zero elements: 700,034,494\n",
      "\n",
      "Memory footprint:\n",
      "  Sparse: 8014.6 MB\n",
      "  Dense: 17068.1 MB (2.1x larger)\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: Check actual batch size being used\n",
    "import torch\n",
    "\n",
    "print(\"=== Diagnostic Information ===\\n\")\n",
    "\n",
    "# Check scVI settings\n",
    "print(f\"scvi.settings.batch_size: {scvi.settings.batch_size}\")\n",
    "print(f\"scvi.settings.dl_num_workers: {scvi.settings.dl_num_workers}\")\n",
    "\n",
    "# Check PyTorch device\n",
    "print(f\"\\nPyTorch device available:\")\n",
    "print(f\"  MPS available: {torch.backends.mps.is_available()}\")\n",
    "print(f\"  MPS built: {torch.backends.mps.is_built()}\")\n",
    "print(f\"  CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Check data type and location\n",
    "print(f\"\\nData information:\")\n",
    "print(f\"  Shape: {adata.shape}\")\n",
    "print(f\"  Backed: {adata.isbacked}\")\n",
    "print(f\"  .X type: {type(adata.X)}\")\n",
    "print(f\"  .X dtype: {adata.X.dtype}\")\n",
    "\n",
    "# Calculate expected batches per epoch\n",
    "n_cells = adata.n_obs\n",
    "batch_size = scvi.settings.batch_size\n",
    "n_batches = n_cells // batch_size + (1 if n_cells % batch_size else 0)\n",
    "print(f\"\\nExpected batches per epoch: {n_batches}\")\n",
    "print(f\"  ({n_cells:,} cells / {batch_size} batch_size)\")\n",
    "\n",
    "# Check sparsity\n",
    "if hasattr(adata.X, 'nnz'):\n",
    "    sparsity = 1 - (adata.X.nnz / (adata.n_obs * adata.n_vars))\n",
    "    print(f\"\\nMatrix sparsity: {sparsity:.2%}\")\n",
    "    print(f\"Non-zero elements: {adata.X.nnz:,}\")\n",
    "    \n",
    "# Memory footprint estimate\n",
    "if hasattr(adata.X, 'data'):\n",
    "    sparse_mb = (adata.X.data.nbytes + adata.X.indices.nbytes + adata.X.indptr.nbytes) / (1024**2)\n",
    "    dense_mb = (adata.n_obs * adata.n_vars * 4) / (1024**2)  # float32\n",
    "    print(f\"\\nMemory footprint:\")\n",
    "    print(f\"  Sparse: {sparse_mb:.1f} MB\")\n",
    "    print(f\"  Dense: {dense_mb:.1f} MB ({dense_mb/sparse_mb:.1f}x larger)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9nzk9ud3uah",
   "metadata": {},
   "source": [
    "### Solution: Try CPU Training\n",
    "\n",
    "**MPS (Apple Silicon GPU) is known to be slow for:**\n",
    "- Large sparse ‚Üí dense matrix operations (which scVI does constantly)\n",
    "- Operations that don't parallelize well\n",
    "- Mixed precision operations\n",
    "\n",
    "**For 877K cells with sparse data, CPU may actually be faster.**\n",
    "\n",
    "Let's test CPU training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81he9yp7lp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using MPS (Apple Silicon GPU)\n",
      "  batch_size: 2048\n",
      "  dl_num_workers: 0\n",
      "  Expected batches/epoch: 428 (~428 batches)\n",
      "\n",
      "use_gpu = True\n",
      "\n",
      "üí° ~100s/epoch is normal for 877K cells with 84% sparse data\n"
     ]
    }
   ],
   "source": [
    "# BACK TO MPS - it was actually the fastest option!\n",
    "use_gpu = True  # Use MPS acceleration\n",
    "\n",
    "# MPS optimized settings\n",
    "scvi.settings.batch_size = 2048  # Larger batches for GPU\n",
    "scvi.settings.dl_num_workers = 0  # Required for MPS\n",
    "\n",
    "print(\"‚úÖ Using MPS (Apple Silicon GPU)\")\n",
    "print(f\"  batch_size: {scvi.settings.batch_size}\")\n",
    "print(f\"  dl_num_workers: {scvi.settings.dl_num_workers}\")\n",
    "print(f\"  Expected batches/epoch: {877141 // 2048} (~428 batches)\")\n",
    "print(f\"\\nuse_gpu = {use_gpu}\")\n",
    "print(f\"\\nüí° ~100s/epoch is normal for 877K cells with 84% sparse data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l3qf2xaxnb",
   "metadata": {},
   "source": [
    "### Alternative: Train on Subset First (for testing)\n",
    "\n",
    "If training is too slow, you can:\n",
    "1. Train on a random subset (e.g., 200K cells) to test speed\n",
    "2. Once optimized, train on full dataset\n",
    "\n",
    "This helps you find optimal settings without waiting hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06lmtc0pwczf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on FULL dataset\n",
      "Full: 877,141 cells √ó 5,101 genes\n"
     ]
    }
   ],
   "source": [
    "# OPTION 2: Train on subset for speed testing (OPTIONAL)\n",
    "USE_SUBSET = False  # Set to True to test on subset first\n",
    "\n",
    "if USE_SUBSET:\n",
    "    print(\"Training on SUBSET for speed testing\")\n",
    "    # Random sample of 200K cells\n",
    "    import numpy as np\n",
    "    np.random.seed(42)\n",
    "    subset_idx = np.random.choice(adata.n_obs, size=200000, replace=False)\n",
    "    adata_subset = adata[subset_idx, :].copy()\n",
    "    \n",
    "    # Re-setup for scVI\n",
    "    scvi.model.SCVI.setup_anndata(\n",
    "        adata_subset,\n",
    "        layer=None,\n",
    "        batch_key='sample_id',\n",
    "    )\n",
    "    print(f\"Subset: {adata_subset.shape[0]:,} cells √ó {adata_subset.shape[1]:,} genes\")\n",
    "    training_data = adata_subset\n",
    "else:\n",
    "    print(\"Training on FULL dataset\")\n",
    "    training_data = adata\n",
    "    print(f\"Full: {training_data.shape[0]:,} cells √ó {training_data.shape[1]:,} genes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5drnt1tk92m",
   "metadata": {},
   "source": [
    "### Optional: Convert dtype for memory efficiency\n",
    "\n",
    "Your data is int64 (8 bytes per value). Converting to float32 (4 bytes) would:\n",
    "- Reduce sparse matrix from 8GB ‚Üí 4GB\n",
    "- Reduce dense matrix from 17GB ‚Üí 8.5GB\n",
    "- Slightly faster training\n",
    "\n",
    "Only do this if you want additional speedup. Not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54bzumw2v5u",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dtype: float32\n",
      "Current memory: 2670.4 MB\n",
      "\n",
      "After conversion:\n",
      "New dtype: float32\n",
      "New memory: 2670.4 MB\n",
      "Saved: 5344.2 MB\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: Convert to float32 for memory efficiency\n",
    "CONVERT_DTYPE = True  # Set to True if you want to save memory\n",
    "\n",
    "if CONVERT_DTYPE:\n",
    "    import numpy as np\n",
    "    print(f\"Current dtype: {adata.X.dtype}\")\n",
    "    print(f\"Current memory: {adata.X.data.nbytes / (1024**2):.1f} MB\")\n",
    "    \n",
    "    # Convert sparse matrix to float32\n",
    "    adata.X = adata.X.astype(np.float32)\n",
    "    \n",
    "    print(f\"\\nAfter conversion:\")\n",
    "    print(f\"New dtype: {adata.X.dtype}\")\n",
    "    print(f\"New memory: {adata.X.data.nbytes / (1024**2):.1f} MB\")\n",
    "    print(f\"Saved: {8014.6 - adata.X.data.nbytes / (1024**2):.1f} MB\")\n",
    "else:\n",
    "    print(\"Keeping original int64 dtype\")\n",
    "    print(\"(Set CONVERT_DTYPE = True to save memory)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "uculuic4y",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU (MPS): True\n",
      "Batch size: 2048\n"
     ]
    }
   ],
   "source": [
    "# Alternative: If MPS is too slow, try CPU with optimized settings\n",
    "# Sometimes CPU can be faster than MPS for large sparse‚Üídense operations\n",
    "\n",
    "# Option A: Use CPU instead (uncomment to try)\n",
    "# import os\n",
    "# os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "# scvi.settings.batch_size = 1024\n",
    "# use_gpu = False  # Force CPU\n",
    "# print(\"Forcing CPU training (may be faster for large sparse datasets)\")\n",
    "\n",
    "# Option B: Continue with MPS but optimized\n",
    "use_gpu = True\n",
    "print(f\"Using GPU (MPS): {use_gpu}\")\n",
    "print(f\"Batch size: {scvi.settings.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "x6c5gfqpny8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "  Device: MPS (GPU)\n",
      "  Cells: 877,141\n",
      "  Batch size: 2048\n",
      "  Expected batches/epoch: 428\n",
      "Epoch 200/200: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [5:43:24<00:00, 99.57s/it, v_num=1, train_loss=2.15e+3]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [5:43:24<00:00, 103.02s/it, v_num=1, train_loss=2.15e+3]\n",
      "\n",
      "‚úì Training complete in 343.4 minutes\n",
      "  Average time per epoch: 103.0s\n"
     ]
    }
   ],
   "source": [
    "# Train scVI model with optimized settings\n",
    "model = scvi.model.SCVI(\n",
    "    adata,  # Will be adata or adata_subset depending on USE_SUBSET\n",
    "    n_layers=2,\n",
    "    n_latent=30,\n",
    "    gene_likelihood='nb',\n",
    ")\n",
    "\n",
    "print(f\"\\nStarting training...\")\n",
    "print(f\"  Device: {'CPU' if not use_gpu else 'MPS (GPU)'}\")\n",
    "print(f\"  Cells: {adata.n_obs:,}\")\n",
    "print(f\"  Batch size: {scvi.settings.batch_size}\")\n",
    "print(f\"  Expected batches/epoch: {adata.n_obs // scvi.settings.batch_size}\")\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "model.train(\n",
    "    max_epochs=200,\n",
    "    early_stopping=True,\n",
    "    early_stopping_patience=15,\n",
    "    accelerator='mps',\n",
    "    plan_kwargs={\n",
    "        'lr': 1e-3,\n",
    "        'reduce_lr_on_plateau': True,\n",
    "        'lr_patience': 8,\n",
    "        'lr_factor': 0.6,\n",
    "    },\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n‚úì Training complete in {elapsed/60:.1f} minutes\")\n",
    "print(f\"  Average time per epoch: {elapsed/len(model.history['elbo_train']):.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6lii2c8og6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added X_scVI to adata.obsm with shape: (877141, 30)\n"
     ]
    }
   ],
   "source": [
    "# Get scVI latent representation\n",
    "adata.obsm['X_scVI'] = model.get_latent_representation()\n",
    "\n",
    "print(f\"Added X_scVI to adata.obsm with shape: {adata.obsm['X_scVI'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f95d7f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write('/Volumes/processing2/RRmap/data/EAE_proseg_clustered_louvain_leiden_all_sections_annotated_rotated_scVI_embedding_for_mana.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3871e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcd22a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad('/Volumes/processing2/RRmap/data/EAE_proseg_clustered_louvain_leiden_all_sections_annotated_rotated_scVI_embedding_for_mana.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49c6a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.3386689e-01,  4.3654990e-01, -2.6233132e+00, ...,\n",
       "         1.1633375e-01,  1.1095801e-01, -1.4505005e-01],\n",
       "       [-7.1471941e-01,  1.0692480e+00, -9.7826135e-01, ...,\n",
       "         1.5827596e-01, -1.4907831e-01,  7.9505849e-01],\n",
       "       [-7.8132939e-01,  1.4583066e+00, -4.2622811e-01, ...,\n",
       "         1.9209170e-01,  3.9817306e-01, -7.7253580e-02],\n",
       "       ...,\n",
       "       [-9.3181431e-03, -5.6185573e-03, -2.7711408e+00, ...,\n",
       "         4.5336545e-01,  9.0515220e-01, -4.5508730e-01],\n",
       "       [-3.4214172e-01,  7.1929544e-01, -1.1241843e+00, ...,\n",
       "         6.3764274e-02,  4.4159770e-02, -6.9451451e-02],\n",
       "       [-2.3385951e-01,  3.4477973e-01, -1.4867914e-01, ...,\n",
       "         4.9205196e-01,  1.9697845e-03,  1.8536758e-01]],\n",
       "      shape=(877141, 30), dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obsm['X_scVI']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jnn34l5yox9",
   "metadata": {},
   "source": [
    "## Part 2: Build Spatial Neighborhoods\n",
    "\n",
    "Build spatial neighborhood graphs for each sample separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "u33beyhyb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christoffer/miniconda3/envs/cellcharter-env-new/lib/python3.12/site-packages/dask/dataframe/__init__.py:31: FutureWarning: The legacy Dask DataFrame implementation is deprecated and will be removed in a future version. Set the configuration option `dataframe.query-planning` to `True` or None to enable the new Dask Dataframe implementation and silence this warning.\n",
      "  warnings.warn(\n",
      "/Users/christoffer/miniconda3/envs/cellcharter-env-new/lib/python3.12/site-packages/xarray_schema/__init__.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial graph built: (877141, 877141)\n",
      "Average neighbors per cell: 6.0\n"
     ]
    }
   ],
   "source": [
    "import squidpy as sq\n",
    "\n",
    "# Build spatial graph\n",
    "# This should be done per-sample to avoid creating edges between samples\n",
    "sq.gr.spatial_neighbors(\n",
    "    adata,\n",
    "    coord_type='generic',\n",
    "    delaunay=True,  # Delaunay triangulation (connects nearby cells)\n",
    "    key_added='spatial',\n",
    "    library_key='sample_id'  # Ensure no edges between different samples,\n",
    ")\n",
    "\n",
    "print(f\"Spatial graph built: {adata.obsp['spatial_connectivities'].shape}\")\n",
    "print(f\"Average neighbors per cell: {adata.obsp['spatial_connectivities'].sum(axis=1).mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74f815ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christoffer/miniconda3/envs/cellcharter-env-new/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cellcharter as cc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893fe5c",
   "metadata": {},
   "source": [
    "### Remove long links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02b2c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.gr.remove_long_links(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6vio3i0h9ls",
   "metadata": {},
   "source": [
    "## Part 3: Run MANA Weighted Aggregation\n",
    "\n",
    "Apply MANA with optimal parameters from MANA-6 benchmarking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "m10u3y1c2o",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MANA functions\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from utils import aggregate_neighbors_weighted, plot_spatial_compact_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85hj9qst6ve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns that might be sample IDs:\n",
      "  - sample_id: 107 unique values\n",
      "  - sample_name: 107 unique values\n",
      "  - _scvi_batch: 107 unique values\n"
     ]
    }
   ],
   "source": [
    "# Run MANA with optimal parameters from MANA-6 benchmarking\n",
    "# Using gaussian kernel (winner from benchmark)\n",
    "# IMPORTANT: Use sample_key for memory-efficient per-sample processing!\n",
    "\n",
    "# First, reload the module to get the updated code\n",
    "import importlib\n",
    "import sys\n",
    "if 'utils.aggregate_neighbors_weighted' in sys.modules:\n",
    "    importlib.reload(sys.modules['utils.aggregate_neighbors_weighted'])\n",
    "from utils.aggregate_neighbors_weighted import aggregate_neighbors_weighted\n",
    "\n",
    "# Check what sample column to use\n",
    "print(\"Available columns that might be sample IDs:\")\n",
    "for col in adata.obs.columns:\n",
    "    if 'sample' in col.lower() or 'batch' in col.lower() or 'section' in col.lower():\n",
    "        print(f\"  - {col}: {adata.obs[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "oeejrsm1apk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 107 samples separately for memory efficiency...\n",
      "  Processing sample 1/107: G3_L1_0 (10,909 cells)\n",
      "  Processing sample 2/107: G3_L1_1 (19,257 cells)\n",
      "  Processing sample 3/107: G3_L1_2 (7,392 cells)\n",
      "  Processing sample 4/107: G3_L2_0 (9,715 cells)\n",
      "  Processing sample 5/107: G3_L2_1 (11,650 cells)\n",
      "  Processing sample 6/107: G3_L2_2 (4,993 cells)\n",
      "  Processing sample 7/107: G3_L3_0 (13,378 cells)\n",
      "  Processing sample 8/107: G3_L3_1 (8,085 cells)\n",
      "  Processing sample 9/107: G3_L3_2 (5,570 cells)\n",
      "  Processing sample 10/107: G4_L1_0 (4,419 cells)\n",
      "  Processing sample 11/107: G4_L1_1 (6,364 cells)\n",
      "  Processing sample 12/107: G4_L1_2 (12,048 cells)\n",
      "  Processing sample 13/107: G4_L2_0 (10,094 cells)\n",
      "  Processing sample 14/107: G4_L2_1 (8,493 cells)\n",
      "  Processing sample 15/107: G4_L2_2 (5,998 cells)\n",
      "  Processing sample 16/107: G4_L3_0 (6,918 cells)\n",
      "  Processing sample 17/107: G4_L3_1 (11,613 cells)\n",
      "  Processing sample 18/107: G4_L3_2 (6,617 cells)\n",
      "  Processing sample 19/107: G5_L1_0 (3,044 cells)\n",
      "  Processing sample 20/107: G5_L1_1 (5,271 cells)\n",
      "  Processing sample 21/107: G5_L1_2 (6,597 cells)\n",
      "  Processing sample 22/107: G5_L2_0 (6,371 cells)\n",
      "  Processing sample 23/107: G5_L2_1 (7,449 cells)\n",
      "  Processing sample 24/107: G5_L2_2 (4,182 cells)\n",
      "  Processing sample 25/107: G5_L3_0 (7,372 cells)\n",
      "  Processing sample 26/107: G5_L3_1 (5,697 cells)\n",
      "  Processing sample 27/107: G5_L3_2 (4,669 cells)\n",
      "  Processing sample 28/107: G6_L1_0 (5,207 cells)\n",
      "  Processing sample 29/107: G6_L1_1 (8,410 cells)\n",
      "  Processing sample 30/107: G6_L1_2 (6,584 cells)\n",
      "  Processing sample 31/107: G6_L2_0 (4,136 cells)\n",
      "  Processing sample 32/107: G6_L2_1 (4,603 cells)\n",
      "  Processing sample 33/107: G6_L2_2 (5,503 cells)\n",
      "  Processing sample 34/107: G6_L3_0 (8,092 cells)\n",
      "  Processing sample 35/107: G6_L3_1 (6,514 cells)\n",
      "  Processing sample 36/107: G6_L3_2 (5,498 cells)\n",
      "  Processing sample 37/107: S1_B1_0 (13,844 cells)\n",
      "  Processing sample 38/107: S1_B1_1 (6,538 cells)\n",
      "  Processing sample 39/107: S1_B1_2 (7,348 cells)\n",
      "  Processing sample 40/107: S1_B2_0 (7,917 cells)\n",
      "  Processing sample 41/107: S1_B2_1 (9,626 cells)\n",
      "  Processing sample 42/107: S1_B2_2 (4,974 cells)\n",
      "  Processing sample 43/107: S1_B3_0 (8,246 cells)\n",
      "  Processing sample 44/107: S1_B3_1 (7,276 cells)\n",
      "  Processing sample 45/107: S1_B3_2 (7,845 cells)\n",
      "  Processing sample 46/107: S1_T1_0 (5,468 cells)\n",
      "  Processing sample 47/107: S1_T1_1 (7,488 cells)\n",
      "  Processing sample 48/107: S1_T1_2 (4,742 cells)\n",
      "  Processing sample 49/107: S1_T2_0 (4,183 cells)\n",
      "  Processing sample 50/107: S1_T2_1 (6,912 cells)\n",
      "  Processing sample 51/107: S1_T2_2 (9,403 cells)\n",
      "  Processing sample 52/107: S1_T3_0 (8,420 cells)\n",
      "  Processing sample 53/107: S1_T3_1 (11,300 cells)\n",
      "  Processing sample 54/107: S1_T3_2 (9,262 cells)\n",
      "  Processing sample 55/107: OS2-1_T (4,722 cells)\n",
      "  Processing sample 56/107: OS2-1_C (8,772 cells)\n",
      "  Processing sample 57/107: S2_B1_2 (8,962 cells)\n",
      "  Processing sample 58/107: S2_B2_0 (12,878 cells)\n",
      "  Processing sample 59/107: S2_B2_1 (9,242 cells)\n",
      "  Processing sample 60/107: S2_B2_2 (5,971 cells)\n",
      "  Processing sample 61/107: S2_B3_0 (10,868 cells)\n",
      "  Processing sample 62/107: OS2-1_L (7,580 cells)\n",
      "  Processing sample 63/107: S2_B3_2 (6,430 cells)\n",
      "  Processing sample 64/107: S2_T1_0 (8,586 cells)\n",
      "  Processing sample 65/107: S2_T1_1 (15,695 cells)\n",
      "  Processing sample 66/107: S2_T1_2 (8,183 cells)\n",
      "  Processing sample 67/107: S2_T2_0 (7,516 cells)\n",
      "  Processing sample 68/107: S2_T2_1 (13,766 cells)\n",
      "  Processing sample 69/107: S2_T2_2 (3,824 cells)\n",
      "  Processing sample 70/107: S2_T3_0 (5,946 cells)\n",
      "  Processing sample 71/107: S2_T3_1 (12,210 cells)\n",
      "  Processing sample 72/107: S4_B1_0 (7,791 cells)\n",
      "  Processing sample 73/107: S4_B1_1 (9,217 cells)\n",
      "  Processing sample 74/107: S4_B1_2 (7,427 cells)\n",
      "  Processing sample 75/107: S4_B2_0 (8,896 cells)\n",
      "  Processing sample 76/107: S4_B2_1 (12,218 cells)\n",
      "  Processing sample 77/107: S4_B2_2 (9,172 cells)\n",
      "  Processing sample 78/107: S4_B3_0 (12,841 cells)\n",
      "  Processing sample 79/107: S4_B3_1 (10,277 cells)\n",
      "  Processing sample 80/107: S4_B3_2 (9,760 cells)\n",
      "  Processing sample 81/107: S4_T1_0 (7,820 cells)\n",
      "  Processing sample 82/107: S4_T1_1 (8,088 cells)\n",
      "  Processing sample 83/107: S4_T1_2 (5,446 cells)\n",
      "  Processing sample 84/107: S4_T2_0 (4,223 cells)\n",
      "  Processing sample 85/107: S4_T2_1 (11,428 cells)\n",
      "  Processing sample 86/107: S4_T2_2 (8,103 cells)\n",
      "  Processing sample 87/107: S4_T3_0 (9,929 cells)\n",
      "  Processing sample 88/107: S4_T3_1 (6,416 cells)\n",
      "  Processing sample 89/107: S4_T3_2 (6,057 cells)\n",
      "  Processing sample 90/107: S3_B1_0 (11,643 cells)\n",
      "  Processing sample 91/107: OS2-2_C (8,182 cells)\n",
      "  Processing sample 92/107: S3_B1_2 (11,624 cells)\n",
      "  Processing sample 93/107: S3_B2_0 (15,297 cells)\n",
      "  Processing sample 94/107: OS2-2_L (5,845 cells)\n",
      "  Processing sample 95/107: OS2-2_T (4,369 cells)\n",
      "  Processing sample 96/107: S3_B3_0 (17,380 cells)\n",
      "  Processing sample 97/107: S3_B3_1 (9,254 cells)\n",
      "  Processing sample 98/107: S3_B3_2 (12,599 cells)\n",
      "  Processing sample 99/107: S3_T1_0 (5,985 cells)\n",
      "  Processing sample 100/107: S3_T1_1 (5,972 cells)\n",
      "  Processing sample 101/107: S3_T1_2 (7,437 cells)\n",
      "  Processing sample 102/107: S3_T2_0 (8,873 cells)\n",
      "  Processing sample 103/107: S3_T2_1 (7,875 cells)\n",
      "  Processing sample 104/107: S3_T2_2 (5,863 cells)\n",
      "  Processing sample 105/107: S3_T3_0 (6,143 cells)\n",
      "  Processing sample 106/107: S3_T3_1 (9,180 cells)\n",
      "  Processing sample 107/107: S3_T3_2 (7,856 cells)\n",
      "\n",
      "MANA aggregation complete!\n",
      "Output stored in adata.obsm['X_mana_gauss'] with shape: (877141, 120)\n"
     ]
    }
   ],
   "source": [
    "# Run MANA with memory-efficient per-sample processing\n",
    "# Adjust 'sample_key' to match your actual sample column name!\n",
    "\n",
    "aggregate_neighbors_weighted(\n",
    "    adata,\n",
    "    n_layers=3,              # Optimal balance (from MANA-5)\n",
    "    aggregations='mean',     # Standard aggregation\n",
    "    use_rep='X_scVI',        # Use scVI latent space\n",
    "    out_key='X_mana_gauss',  # Output key\n",
    "    hop_decay=0.2,           # Optimal decay (from MANA-4)\n",
    "    distance_kernel='gaussian',  # Winner from MANA-6 benchmark\n",
    "    spatial_key='spatial',\n",
    "    normalize_weights=True,\n",
    "    include_self=True,\n",
    "    sample_key='sample_id',  # CRITICAL: Process per-sample to avoid memory issues!\n",
    ")\n",
    "\n",
    "print(\"\\nMANA aggregation complete!\")\n",
    "print(f\"Output stored in adata.obsm['X_mana_gauss'] with shape: {adata.obsm['X_mana_gauss'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xe3o64sx98k",
   "metadata": {},
   "source": [
    "## Part 4: Clustering on MANA Features\n",
    "\n",
    "Cluster cells based on the MANA-aggregated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pzzx7nejjqd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build neighborhood graph in MANA feature space\n",
    "sc.pp.neighbors(\n",
    "    adata,\n",
    "    use_rep='X_mana_gauss',\n",
    "    n_neighbors=15,\n",
    "    key_added='mana'\n",
    ")\n",
    "\n",
    "print(\"Neighbor graph built in MANA feature space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vj7ilqrtble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leiden clustering\n",
    "# Try a few resolutions to see what works best\n",
    "resolutions = [0.3, 0.5, 0.8, 1.0]\n",
    "\n",
    "for res in resolutions:\n",
    "    sc.tl.leiden(\n",
    "        adata,\n",
    "        resolution=res,\n",
    "        key_added=f'leiden_mana_{res}',\n",
    "        neighbors_key='mana'\n",
    "    )\n",
    "    n_clusters = adata.obs[f'leiden_mana_{res}'].nunique()\n",
    "    print(f\"Resolution {res}: {n_clusters} clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ysa6kuu1pc",
   "metadata": {},
   "source": [
    "## Part 5: Visualization\n",
    "\n",
    "Visualize the MANA clustering results across all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1uats4zlmwj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MANA clustering (resolution 0.5 as starting point)\n",
    "plot_spatial_compact_fast(\n",
    "    adata,\n",
    "    color='leiden_mana_0.5',\n",
    "    groupby='sample_id',  # Adjust to your actual sample column\n",
    "    spot_size=8,\n",
    "    cols=3,\n",
    "    height=10,\n",
    "    background='white',\n",
    "    dpi=120\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ujmuyhjh84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP visualization in MANA space\n",
    "sc.tl.umap(adata, neighbors_key='mana')\n",
    "\n",
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=['leiden_mana_0.5', 'sample_id'],\n",
    "    ncols=2,\n",
    "    frameon=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mzjt2f6uyve",
   "metadata": {},
   "source": [
    "## Part 6: Quality Control & Evaluation\n",
    "\n",
    "Evaluate the clustering quality using metrics from MANA-6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2gf6q66kt8z",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "# Helper function from MANA-6\n",
    "def local_purity(adata, cluster_key):\n",
    "    \"\"\"Compute spatial coherence: fraction of neighbors with same cluster label.\"\"\"\n",
    "    conn = adata.obsp['spatial_connectivities']\n",
    "    labels = adata.obs[cluster_key].astype('category').cat.codes.values\n",
    "    purities = []\n",
    "    \n",
    "    for i in range(adata.n_obs):\n",
    "        neighbors = conn[i].nonzero()[1]\n",
    "        if len(neighbors) > 0:\n",
    "            neighbor_labels = labels[neighbors]\n",
    "            purity = (neighbor_labels == labels[i]).mean()\n",
    "            purities.append(purity)\n",
    "    \n",
    "    return np.mean(purities)\n",
    "\n",
    "# Evaluate clustering\n",
    "cluster_key = 'leiden_mana_0.5'\n",
    "\n",
    "# Spatial coherence\n",
    "purity = local_purity(adata, cluster_key)\n",
    "print(f\"Local purity (spatial coherence): {purity:.3f}\")\n",
    "\n",
    "# Expression coherence (in scVI space)\n",
    "labels = adata.obs[cluster_key].astype('category').cat.codes.values\n",
    "sil = silhouette_score(adata.obsm['X_scVI'], labels, metric='euclidean', sample_size=10000)\n",
    "print(f\"Silhouette score (expression coherence): {sil:.3f}\")\n",
    "\n",
    "# Cluster sizes\n",
    "print(f\"\\nCluster sizes:\")\n",
    "print(adata.obs[cluster_key].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s77pons2d5c",
   "metadata": {},
   "source": [
    "## Part 7: Save Results\n",
    "\n",
    "Save the annotated data with MANA clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hq00w8cgode",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save annotated data\n",
    "output_path = '/Volumes/processing2/RRmap/data/EAE_MANA_annotated.h5ad'\n",
    "\n",
    "# Optional: clean up .uns to avoid serialization issues\n",
    "# Remove problematic entries if they exist\n",
    "if 'cytetype_jobDetails' in adata.uns:\n",
    "    del adata.uns['cytetype_jobDetails']\n",
    "\n",
    "adata.write_h5ad(output_path)\n",
    "print(f\"Saved annotated data to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89kywruszd",
   "metadata": {},
   "source": [
    "## Optional: Compare with CellCharter\n",
    "\n",
    "To validate MANA's superiority on this full dataset, run CellCharter for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sb71477saak",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CellCharter (uniform weights, no distance weighting)\n",
    "aggregate_neighbors_weighted(\n",
    "    adata,\n",
    "    n_layers=3,\n",
    "    aggregations='mean',\n",
    "    use_rep='X_scVI',\n",
    "    out_key='X_cellcharter',\n",
    "    hop_decay=1.0,  # Uniform weights\n",
    "    distance_kernel='none',  # No distance weighting\n",
    "    spatial_key='spatial',\n",
    "    normalize_weights=True,\n",
    "    include_self=True,\n",
    ")\n",
    "\n",
    "# Cluster with CellCharter features\n",
    "sc.pp.neighbors(adata, use_rep='X_cellcharter', n_neighbors=15, key_added='cellcharter')\n",
    "sc.tl.leiden(adata, resolution=0.5, key_added='leiden_cellcharter', neighbors_key='cellcharter')\n",
    "\n",
    "print(\"CellCharter aggregation and clustering complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mipts0baap",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare MANA vs CellCharter\n",
    "print(\"=== MANA vs CellCharter Comparison ===\\n\")\n",
    "\n",
    "# MANA metrics\n",
    "mana_purity = local_purity(adata, 'leiden_mana_0.5')\n",
    "mana_labels = adata.obs['leiden_mana_0.5'].astype('category').cat.codes.values\n",
    "mana_sil = silhouette_score(adata.obsm['X_scVI'], mana_labels, metric='euclidean', sample_size=10000)\n",
    "\n",
    "# CellCharter metrics\n",
    "cc_purity = local_purity(adata, 'leiden_cellcharter')\n",
    "cc_labels = adata.obs['leiden_cellcharter'].astype('category').cat.codes.values\n",
    "cc_sil = silhouette_score(adata.obsm['X_scVI'], cc_labels, metric='euclidean', sample_size=10000)\n",
    "\n",
    "print(f\"Local Purity (Spatial Coherence):\")\n",
    "print(f\"  MANA:        {mana_purity:.3f}\")\n",
    "print(f\"  CellCharter: {cc_purity:.3f}\")\n",
    "print(f\"  Improvement: {((mana_purity - cc_purity) / cc_purity * 100):+.1f}%\\n\")\n",
    "\n",
    "print(f\"Silhouette Score (Expression Coherence):\")\n",
    "print(f\"  MANA:        {mana_sil:.3f}\")\n",
    "print(f\"  CellCharter: {cc_sil:.3f}\")\n",
    "print(f\"  Difference:  {(mana_sil - cc_sil):+.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellcharter-env-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
